---
title: kubeadm component config management
authors:
  - "@rosti"
owning-sig: sig-cluster-lifecycle
participating-sigs:
  - sig-cluster-lifecycle
reviewers:
  - "@fabriziopandini"
  - "@neolit123"
  - "@ereslibre"
  - "@yastij"
approvers:
  - "@timothysc"
editor: "@rosti"
creation-date: 2019-09-25
last-updated: 2019-09-25
status: implementable
see-also:
  - "/keps/sig-cluster-lifecycle/kubeadm/0023-kubeadm-config.md"
  - "/keps/sig-cluster-lifecycle/kubeadm/20190722-Advanced-configurations-with-kubeadm-(Kustomize).md"
---

# kubeadm component config management

## Table of Contents

<!-- toc -->
- [Release Signoff Checklist](#release-signoff-checklist)
- [Summary](#summary)
- [Motivation](#motivation)
  - [Goals](#goals)
  - [Non-Goals](#non-goals)
- [Proposal](#proposal)
  - [Stop Component Config defaulting](#stop-component-config-defaulting)
  - [Delegate config validation to the components](#delegate-config-validation-to-the-components)
  - [Kubernetes Core vs AddOns Component Configs](#kubernetes-core-vs-addons-component-configs)
    - [AddOn Component Config management](#addon-component-config-management)
    - [Kubernetes Core Component Config management](#kubernetes-core-component-config-management)
      - [Generated Kubernetes Core Component Config management](#generated-kubernetes-core-component-config-management)
      - [User supplied Kubernetes Core Component Config management](#user-supplied-kubernetes-core-component-config-management)
      - [Allow Kustomize use over core Kubernetes component configs](#allow-kustomize-use-over-core-kubernetes-component-configs)
  - [Stop using component config internal types](#stop-using-component-config-internal-types)
  - [(OPTIONAL) “kubeadm upgrade plan” changes](#optional-kubeadm-upgrade-plan-changes)
  - [Risks and Mitigations](#risks-and-mitigations)
    - [Users will have to manually migrate more Kubernetes core component configs than before](#users-will-have-to-manually-migrate-more-kubernetes-core-component-configs-than-before)
    - [Users will have to manually migrate more AddOn component configs than before](#users-will-have-to-manually-migrate-more-addon-component-configs-than-before)
    - [Users will loose track of what needs manual migration and what not](#users-will-loose-track-of-what-needs-manual-migration-and-what-not)
- [Design Details](#design-details)
  - [Test Plan](#test-plan)
  - [Graduation Criteria](#graduation-criteria)
  - [Upgrade / Downgrade Strategy](#upgrade--downgrade-strategy)
  - [Version Skew Strategy](#version-skew-strategy)
- [Implementation History](#implementation-history)
  - [09/25/2019](#09252019)
<!-- /toc -->

## Release Signoff Checklist

- [ ] kubernetes/enhancements issue in release milestone, which links to KEP (this should be a link to the KEP location in kubernetes/enhancements, not the initial KEP PR)
- [X] KEP approvers have set the KEP status to `implementable`
- [X] Design details are appropriately documented
- [ ] Test plan is in place, giving consideration to SIG Architecture and SIG Testing input
- [ ] Graduation criteria is in place
- [ ] "Implementation History" section is up-to-date for milestone
- [ ] User-facing documentation has been created in [kubernetes/website], for publication to [kubernetes.io]
- [ ] Supporting documentation e.g., additional design documents, links to mailing list discussions/SIG meetings, relevant PRs/issues, release notes

## Summary

This document outlines a model by which kubeadm will manage component configs other than its own.

## Motivation

For a long time now, kubeadm has been using component configs for kubelet and kube-proxy. These configs are usually generated by kubeadm by using a default component config as a basis and adding setup specific details (either opinionated by kubeadm itself, or supplied via some of the kubeadm’s config objects).  
There is support for users to supply their own component configs along with the kubeadm specific config objects upon kubeadm init. Kubeadm validates, defaults and stores these config on the cluster in the form of config maps. It also supplies these configs in one way or another to the target component itself.  
There is also a desire and code has been historically structured in a way, to allow kubeadm to convert component config formats upon upgrade, should the need for that arise.

Hence, the following problems have been observed:
- Internal types have been used to allow for defaulting, validating and migrating component configs. This cannot continue if kubeadm is to move out of the kubernetes/kubernetes repository.
- Defaulting the configs, that are generated by kubeadm or supplied by users, populates additional fields with default values. This makes it difficult to determine in retrospect, what fields were set on purpose with their default values, and what fields were simply automatically filled in by the defaulting code.
- Providing support for validation by vendoring component specific code can lead to false-positive and missed errors. This can be caused by the deviation between the imported code by kubeadm and the actual component.
- Migrating between config versions also requires code to be vendored in or forked from the components. This can also lead to difficult to diagnose errors and changed behaviour in unexpected ways.
- Not distinguishing between kubeadm generated and user supplied component configs, necessitates the requirement for config migration. Kubeadm generated configs that are not modified by users directly in the config map, can be fully regenerated upon config format change. In all other cases kubeadm must convert the config to preserve user changes.

These observations along with the emergence of kubeadm phases, kustomize support and work around addon operators allows us to have the following future goals.

### Goals

- Stop vendoring internal types and validation, defaulting and conversion code.
- Stop defaulting component configs.
- Outsource validation to the component binaries themselves.
- Distinguish between user supplied and kubeadm generated and unmodified component configs.
- Eradicate the need to convert configs.
- Use more community wide solutions, like Kustomize, kubeadm phases and addon operators.
- Provide for as clean as possible upgrade path for existing clusters.

### Non-Goals

- Change the handling of kubeadm’s own config types in any way.
- Cover in any way the migration of command line flags to component configs.
- Define strategies for config map naming and backup.

## Proposal

### Stop Component Config defaulting

Component config defaulting has a number of issues:
- It’s difficult to tell in retrospect if a setting value was intended or simply defaulted.
- If a default value changes a defaulted setting will stop us from using the new value.
- Defaulting bloats the resulting config, thus making it hard for users to migrate it upon a version change.

Hence, kubeadm should stop defaulting component configs and leave this to components themselves.

### Delegate config validation to the components

Currently, kubeadm vendors in pieces of Go code from the components to be able to perform component config validation. This is a bad practice as it bloats the kubeadm dependencies and deviation between the vendored code and the components can lead to inconsistencies.  
To solve this, validation is going to be performed by executing a container or the binary of the component to be used with an appropriate command to verify the supplied config.  
If a target component does not have any means to verify its config, then kubeadm won’t do any validation for the time being. It will instead display a warning to the user denoting that certain component’s config is unvalidated.

### Kubernetes Core vs AddOns Component Configs

Currently kubeadm maintains the component configs of both kubelet and kube-proxy. These are components that are maintained in very different ways.

Kubelet, along with API Server, Scheduler, Controller Manager and etcd, are deemed essential Kubernetes components. They are deployed and managed locally by kubeadm, using systemd services (kubelet) or static pods on the local kubelet (API Server, Scheduler, etc.). Hence, their configs are usually consumed by the components in the form of local files.

On the other hand, kube-proxy and CoreDNS/kube-dns are addons, that are managed as standard Kubernetes deployments. Hence their configs are usually accessed via config maps.

Therefore, two different config lifecycles are distinguishable here - one for Kubernetes core components and one for cluster addons.

The defaulting and validation changes, proposed in the previous paragraphs, are going to be applied to both Kubernetes core and AddOn component config types.

#### AddOn Component Config management

AddOn component configs are always stored in config maps. They can be supplied in their entirety by users along with the kubeadm config during init or can be generated by kubeadm itself.
If, upon upgrade, kubeadm detects an obsolete config version, it will bail out with an error message, asking users to upgrade the addon config by hand.

The ultimate goal for addon component configs, is for them to be eventually managed in their entirety by cluster addon operators, instead of kubeadm.

#### Kubernetes Core Component Config management

Like in the addon case, Kubernetes core component configs can be specified by users in their entirety along with the kubeadm config during init or in a config map. On the other hand, if those configs are not user supplied, they are generated by kubeadm.
User supplied configs need to be stored in config maps and have to be manually converted by users upon upgrade, while kubeadm generated ones need neither of these things.  
As most users would choose kubeadm to generate and manage Kubernetes core component configs itself, it is a viable proposition to treat generated and user supplied configs differently.

##### Generated Kubernetes Core Component Config management

Whenever kubeadm does not find component configs, in its config file or in a set of well known config maps, it will opt in for generation.  
Generated core configs won’t be stored in config maps. Instead, they will always be regenerated in their entirety. This will allow seamless component config version upgrades when users have delegated config management responsibility to kubeadm.

##### User supplied Kubernetes Core Component Config management

As user changes need to be maintained, user supplied configs are stored config maps.  
However, in those cases kubeadm is not responsible for config migration upon upgrade. If the new component version is unable to consume the user supplied config, kubeadm is going to bail out with an error message, prompting the user to perform a manual config migration beforehand. This is a behavior similar to that for addon configs.

##### Allow Kustomize use over core Kubernetes component configs

Kubeadm shall extend its current Kustomize support to include patching of core Kubernetes component configs. Currently, this will include only kubelet’s component config. However, in the future this might extend to the API Server, Scheduler and Controller Manager as well.  
Most notably, this feature is not going to be applied to kube-proxy’s config by kubeadm as this is an addon component config and the responsibility for this is going to be with the corresponding addon operator.

Kustomize patches will be applied on both user supplied and kubeadm generated core component configs, just before they are stored in the local files from which the config will be consumed by the components. In the case of user supplied core component configs, neither the Kustomize patches, nor the result after applying them is going to be stored on the cluster. The config maps are going to contain only the vanilla user supplied component configs.

If a user has provided Kustomize patches for a config version, that is different from the current one, kubeadm is going to bail out with an error, prompting the user to either delete the old patches, or to upgrade them to the new version. This is best implemented using a kubeadm pre-flight check.

UX wise, this feature is going to be reusing the existing kubeadm options that were introduced with the implementation of the kubeadm advanced configurations KEP. This allows for kustomizations to be applied to component configs on a per-node basis during init, join and upgrade just before the config is supposed to be stored on the local node file.

### Stop using component config internal types

As kubeadm will no longer default, validate or migrate component configs inside its code base, the need to use component config internal types is no longer needed. In that case the usage of internal types can be removed. This would also allow us to reduce the number of imported packages and to drop one of the last dependencies on the kubernetes/kubernetes code base.  
The switch is going to be performed by replacing each internal type with a corresponding versioned type. This, by itself, is not going to have any impact on users.

### (OPTIONAL) “kubeadm upgrade plan” changes
As supported component configs are expected to increase in number in the future and some of them might require manual user migration prior to upgrade, an ahead of time notice about what actions are required is a nice thing to have.  
Hence, the “kubeadm upgrade plan” command is going to provide information on the component configs. In particular, if they are managed by kubeadm or are user supplied, and if they need manual upgrade or not.

### Risks and Mitigations

#### Users will have to manually migrate more Kubernetes core component configs than before

In general, most of the users are expected to change only a few fields in the core Kubernetes component configs.
Thus, such configs are better managed by maintaining a Kustomize patch set, rather than a full blown component config.  
With a proper documentation in place, users will be encouraged to opt in for more kubeadm generated configs and Kustomize patch sets, when necessary.

#### Users will have to manually migrate more AddOn component configs than before

For user supplied AddOn configs, that have changed config versions, this might be somewhat true.  
In the long run, addon operators are expected to manage component configs.

#### Users will loose track of what needs manual migration and what not

The proposed changes to the "kubeadm upgrade plan" command will mitigate this risk, as kubeadm users are required to run that command prior to performing an actual upgrade.

## Design Details

### Test Plan

In addition to unit tests, extensive E2E tests should be created to verify various aspects if the implementation.  
Most notably E2E tests should be written to verify different aspects of:
- AddOn and Kubernetes core component configs
- Configs supplied by users or generated by kubeadm
- behavior during kubeadm init and upgrade

### Graduation Criteria

Implementing the accepted proposal in full with sufficient test coverage is the bare minimum for graduation to beta.
However, as this is only an initial version of the proposal and further changes are expected over time. It's likely that the graduation criteria will change in the course of some alpha iterations.

### Upgrade / Downgrade Strategy

Upon upgrade to the new component config strategy, kubeadm users can do one of the following:

- Delete old config maps and allow kubeadm to regenerate the configs.
- Keep old configs untouched, but refuse an upgrade if an issue is discovered (e.g. old config format is no longer accepted by the component).

### Version Skew Strategy

N/A

## Implementation History

### 09/25/2019
- Document created with Summary, Motivation, Proposal and other sections
